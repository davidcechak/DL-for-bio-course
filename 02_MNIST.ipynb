{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidcechak/DL-for-bio-course/blob/master/02_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries setup"
      ],
      "metadata": {
        "id": "f1TIRdTAiT6c"
      }
    },
    {
      "metadata": {
        "id": "PtKvmZx-WmUu"
      },
      "cell_type": "code",
      "source": [
        "!pip install -q torchmetrics"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preparation and exploration"
      ],
      "metadata": {
        "id": "oJqJ4hlLiac4"
      }
    },
    {
      "metadata": {
        "id": "lCsBCXMwbpH5"
      },
      "cell_type": "code",
      "source": [
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "train_dataset = dsets.MNIST(root = './data', train = True, transform = transforms.ToTensor(), download = True)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch dataset implements two methods\n",
        "\n",
        "\n",
        "```\n",
        "__len__ #length of the dataset\n",
        "__getitem__ #access to a single datapoint\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "TB7eV_wBinCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset.__len__())"
      ],
      "metadata": {
        "id": "6BaDVNb7_zS9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8c17046-3927-46a3-aa66-7ecee1bed02a"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counts = {num:0 for num in range(10)}\n",
        "for x,y in train_dataset:\n",
        "  counts[y]+=1\n",
        "\n",
        "counts"
      ],
      "metadata": {
        "id": "ksy7qbE2Uarp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34a78063-1ae0-47bd-da86-cf772f75b7a5"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 5923,\n",
              " 1: 6742,\n",
              " 2: 5958,\n",
              " 3: 6131,\n",
              " 4: 5842,\n",
              " 5: 5421,\n",
              " 6: 5918,\n",
              " 7: 6265,\n",
              " 8: 5851,\n",
              " 9: 5949}"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_index = 123 #from 0 to 59999\n",
        "sample_X, sample_y = train_dataset.__getitem__(sample_index)"
      ],
      "metadata": {
        "id": "NrvayHlK_626"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_image = transforms.ToPILImage()\n",
        "resize = transforms.Resize((100,100))\n",
        "print(sample_y)\n",
        "resize(to_image(sample_X))\n"
      ],
      "metadata": {
        "id": "RLA659eC-OoC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "outputId": "e552fa5f-4d0b-4bff-bf47-63507f4e1022"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=100x100>"
            ],
            "image/png": "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\n",
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCABkAGQBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+iiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiniKRvuox+grR0/Qr2/kCpBLyeuw10Q+G+okA4fn/ZrQ0n4S6lql2IA7JnuRiumH7PGqEZ+2r+YpH/Z41RULfbV49xXF+JfhvqHh3cZC0gXuBXElSpwQQfekooortfB3gceJrhIzIVzivZtK+C1pDGhknU49c12+keEtK0aI7khbHUla0DeaAhw0lsD9KyLnxfoGn3RRJrZWHcCm/wDCw9J/5/Ifzrb0TX7XW1c28qSBeu2s3xxbWZ8OXTyxx7sdSK+QNdEY1F/Lxt9qzKKKK9R+Fviu00TVEN5KEjAHJr0fVvjHbQrILSdWwDjpXm998atdnM0QVdjEgHPauUm8balM5dnIJ/2qxbvUbm8nMryvuP8AtGtLQdF1PXLxIrbzH+YbvmPSvqb4eeE4/C2mNIWfdImX3HpXIfFrxnDb28thFKMuvSvm6WRpX3N1plFFFFFFFT2trJdzCOMZY19L/CfwY+lwre3EeA6Zzj2ro/Hfjaz8Pae8LSbZHTC896+VvEWtTa3qDTzPuOTg+1Y9FFFFFFFOSKST7iM30Ga9v+GXwwnvLaDWLjAibHyNwa9X8S65a+E9BVA6Z2FQFbpXyz4p8SXet6hI0szMgc7Qa52iiiiiiipoLaa5cJFGzknHFe1fDH4ftdwpc3sBXB+64r13WdX07wtopgjmiR0z8gr5o8b+MrnW7uSESP5YbjniuJJJOT1ooooooop8UbSypGoyzEACvbfhv8OLndHdX1uVX7y5HUV6t4h8RWfhHT2SMosiqMDAFfM/jPxfda/qssxkba3YNxXJEljknJpKKKKKKKAMkCvXvhl8OTqt0l1ew7owQ6HHpXt/inXU8MaF5cb7HjiASvlzxT401LxDdu1zLvGSOtcrRRRRRRRRVvTrY3V0qD1FfXHgrTW0rwmlyccQFuPpXz98QfHFzrGpS26SsFjcqRXnpOSTRRRRRRRRRWpoP/IRT6ivsLR/+RCX/r2b+Rr4513/AJD19/12b+dZ9FFFFFFFf//Z\n"
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_X"
      ],
      "metadata": {
        "id": "xS2-X6UtBK-c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de024e6d-c5a2-42d0-8847-be312410fbe4"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.1490, 0.4431, 0.4431, 0.4431, 0.4471, 0.9333,\n",
              "          0.9922, 0.9922, 0.9922, 1.0000, 0.8078, 0.3451, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2235,\n",
              "          0.3333, 0.5765, 0.9176, 0.9882, 0.9882, 0.9882, 0.9922, 0.9882,\n",
              "          0.9882, 0.9882, 0.9882, 0.9922, 0.9882, 0.9647, 0.2941, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2627, 0.7725, 0.9176,\n",
              "          0.9882, 0.9922, 0.9882, 0.9882, 0.9882, 0.9882, 0.7686, 0.7647,\n",
              "          0.7647, 0.7647, 0.7647, 0.9922, 0.9882, 0.9882, 0.3294, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3333, 0.9882, 0.9882,\n",
              "          0.9882, 0.8824, 0.8745, 0.4471, 0.3294, 0.3294, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0627, 0.9922, 0.9882, 0.8392, 0.1098, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1490, 0.8667, 0.6157,\n",
              "          0.4392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0627, 0.7961, 0.9922, 0.9882, 0.4627, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.1020, 0.8118, 0.9922, 1.0000, 0.6588, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.4078, 0.9882, 0.9882, 0.8431, 0.1294, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2627,\n",
              "          0.9412, 0.9882, 0.8627, 0.1216, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1137, 0.7098,\n",
              "          0.9882, 0.8510, 0.1451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9922, 0.9882,\n",
              "          0.9882, 0.3294, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.2980, 0.7490, 1.0000, 0.8431,\n",
              "          0.4314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0745, 0.7686, 0.9882, 0.9922, 0.4745,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.2627, 0.8196, 0.9882, 0.9882, 0.2196, 0.0235,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.1137, 0.7098, 0.9882, 0.8510, 0.3294, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.9922, 0.9882, 0.9882, 0.3294, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0510,\n",
              "          0.7490, 1.0000, 0.8431, 0.1216, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6039,\n",
              "          0.9882, 0.9922, 0.4745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0510, 0.7333,\n",
              "          0.9882, 0.5216, 0.0235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2235, 0.9882,\n",
              "          0.9882, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2235, 0.9882,\n",
              "          0.9882, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "          0.0000, 0.0000, 0.0000, 0.0000]]])"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "#Check if the data is preprocessed and normalized\n",
        "\n",
        "print('Shape:' ,sample_X.size())\n",
        "print('Std:', torch.std_mean(sample_X))\n",
        "print('Max:', torch.max(sample_X))\n",
        "print('Min:', torch.min(sample_X))"
      ],
      "metadata": {
        "id": "FWh4aeaMBZPc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9af7ab4-767f-4698-ceb9-7f4db5ca6ade"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: torch.Size([1, 28, 28])\n",
            "Std: (tensor(0.2991), tensor(0.1220))\n",
            "Max: tensor(1.)\n",
            "Min: tensor(0.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data loading"
      ],
      "metadata": {
        "id": "cmsAIPMekxSc"
      }
    },
    {
      "metadata": {
        "id": "rfDPBdnYgfGp"
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_X, batch_y = next(iter(train_loader))\n",
        "print(batch_X.size())\n",
        "print(batch_y.size())"
      ],
      "metadata": {
        "id": "-VPBPg6cDFez",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08630563-4364-4769-9752-db2b9b758ee6"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 1, 28, 28])\n",
            "torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_y"
      ],
      "metadata": {
        "id": "qnDJJHYFDaGP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f9c42a1-a50b-4f41-eb66-fed982923a18"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 2, 7, 6, 9, 6, 3, 4, 4, 2, 6, 8, 7, 1, 6, 2, 6, 0, 2, 8, 7, 1, 0, 4,\n",
              "        1, 6, 3, 5, 8, 1, 8, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "4xBBpcUip_mB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic regression model"
      ],
      "metadata": {
        "id": "g-1QK42vT_W-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "# Using pytorch nn.Module class\n",
        "class LogisticRegressionClassifier(nn.Module):\n",
        "  def __init__(self, input_size, num_classes):\n",
        "    super().__init__()\n",
        "\n",
        "    self.linear = nn.Linear(input_size, num_classes)\n",
        "    self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.linear(x)\n",
        "    out = self.softmax(out)\n",
        "    return out"
      ],
      "metadata": {
        "id": "IdfVUszmY01Z"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MLP"
      ],
      "metadata": {
        "id": "3_tDofQSTukS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super().__init__()\n",
        "    #TODO\n",
        "    #hint: use nn.ReLU() layer\n",
        "\n",
        "  def forward(self,x):\n",
        "    # TODO\n",
        "    pass"
      ],
      "metadata": {
        "id": "urUq_Yuj0Txn"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the MLP\n",
        "# net = MLP(input_size=28*28, hidden_size = 100, num_classes=10)\n",
        "# sample_input = torch.rand(1,784)\n",
        "# net(sample_input)"
      ],
      "metadata": {
        "id": "N2BChhYS0PyT"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model creation"
      ],
      "metadata": {
        "id": "vc2lCG16T41N"
      }
    },
    {
      "metadata": {
        "id": "-3EPEqbjjfAT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e476fd4-d8da-41cd-9098-e1638e4459ba"
      },
      "cell_type": "code",
      "source": [
        "# Pixels on input will be spreaded out\n",
        "net = LogisticRegressionClassifier(input_size=28*28, num_classes=10)\n",
        "net"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegressionClassifier(\n",
              "  (linear): Linear(in_features=784, out_features=10, bias=True)\n",
              "  (softmax): Softmax(dim=-1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_input = torch.rand(1, 784)"
      ],
      "metadata": {
        "id": "3siFKMlzmtNQ"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net(test_input)"
      ],
      "metadata": {
        "id": "gPRAGPgbmrH2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9aace4ef-e8f7-4ce0-ec18-54c823394e68"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1736, 0.0615, 0.0618, 0.0513, 0.0978, 0.0516, 0.1667, 0.1347, 0.1051,\n",
              "         0.0958]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_X, batch_y = next(iter(train_loader))\n",
        "net(batch_X)"
      ],
      "metadata": {
        "id": "ktO6ndh4XubU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "366fe4d0-4159-44a0-a32a-c9bf259887b9"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (896x28 and 784x10)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1610480181.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-789171083.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (896x28 and 784x10)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Our data shape doesnt match the network input shape\n",
        "batch_X.size()"
      ],
      "metadata": {
        "id": "7aOdzuAvJ5hw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12f00fa1-c061-41eb-9602-d0fbc04d9294"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_X = batch_X.reshape(-1,28*28)\n",
        "batch_X.size()"
      ],
      "metadata": {
        "id": "HkxPZLtOJ8eh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "589e10ac-8c41-4546-bef9-d944876568f9"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 784])"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net(batch_X)"
      ],
      "metadata": {
        "id": "QvK9JmeoX_xJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c51c091-6e51-4092-bace-eb80fcfbbd1e"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1405, 0.0779, 0.0804, 0.0961, 0.0958, 0.1034, 0.1031, 0.1049, 0.0946,\n",
              "         0.1033],\n",
              "        [0.1439, 0.0744, 0.0844, 0.1036, 0.0937, 0.0711, 0.1703, 0.0692, 0.1079,\n",
              "         0.0816],\n",
              "        [0.1228, 0.0850, 0.1011, 0.0945, 0.0793, 0.0858, 0.1289, 0.0893, 0.1167,\n",
              "         0.0966],\n",
              "        [0.1744, 0.0664, 0.1030, 0.0903, 0.0773, 0.1007, 0.0896, 0.1010, 0.1156,\n",
              "         0.0818],\n",
              "        [0.1479, 0.0874, 0.0868, 0.1197, 0.0898, 0.0859, 0.1121, 0.0947, 0.0905,\n",
              "         0.0853],\n",
              "        [0.1431, 0.1019, 0.0853, 0.0900, 0.0927, 0.0744, 0.1216, 0.1042, 0.0950,\n",
              "         0.0918],\n",
              "        [0.1125, 0.0787, 0.0854, 0.0988, 0.1084, 0.1027, 0.1252, 0.0971, 0.0920,\n",
              "         0.0992],\n",
              "        [0.1154, 0.0851, 0.1038, 0.1071, 0.0811, 0.1055, 0.1005, 0.1167, 0.0847,\n",
              "         0.1000],\n",
              "        [0.1482, 0.1003, 0.1101, 0.1010, 0.0796, 0.0916, 0.1005, 0.0896, 0.0954,\n",
              "         0.0837],\n",
              "        [0.1536, 0.0881, 0.0945, 0.0891, 0.0870, 0.0909, 0.1068, 0.0875, 0.1066,\n",
              "         0.0960],\n",
              "        [0.1275, 0.0820, 0.0994, 0.1092, 0.0779, 0.0987, 0.1148, 0.0818, 0.1080,\n",
              "         0.1007],\n",
              "        [0.1515, 0.0931, 0.0856, 0.1007, 0.0951, 0.0804, 0.0918, 0.0891, 0.1083,\n",
              "         0.1045],\n",
              "        [0.1418, 0.0809, 0.0975, 0.0986, 0.1056, 0.0751, 0.1012, 0.0931, 0.1031,\n",
              "         0.1033],\n",
              "        [0.1111, 0.0823, 0.0891, 0.0998, 0.0973, 0.1132, 0.1244, 0.0943, 0.0897,\n",
              "         0.0988],\n",
              "        [0.1674, 0.0920, 0.1029, 0.0930, 0.0710, 0.1064, 0.0959, 0.0945, 0.0910,\n",
              "         0.0858],\n",
              "        [0.1758, 0.0885, 0.0849, 0.0876, 0.0891, 0.0731, 0.1162, 0.0873, 0.1031,\n",
              "         0.0946],\n",
              "        [0.1500, 0.0803, 0.0991, 0.0883, 0.0963, 0.0793, 0.1190, 0.1028, 0.0826,\n",
              "         0.1022],\n",
              "        [0.0944, 0.0791, 0.0994, 0.1133, 0.0870, 0.1001, 0.1207, 0.1131, 0.1107,\n",
              "         0.0823],\n",
              "        [0.2011, 0.0977, 0.0837, 0.0763, 0.0770, 0.0598, 0.1358, 0.0918, 0.0893,\n",
              "         0.0874],\n",
              "        [0.1844, 0.0714, 0.0793, 0.0849, 0.0862, 0.0901, 0.1392, 0.0960, 0.0971,\n",
              "         0.0713],\n",
              "        [0.1738, 0.0959, 0.0916, 0.0843, 0.1016, 0.0756, 0.0821, 0.0980, 0.1036,\n",
              "         0.0934],\n",
              "        [0.1210, 0.0834, 0.0882, 0.1101, 0.0858, 0.0964, 0.1212, 0.0913, 0.1004,\n",
              "         0.1022],\n",
              "        [0.1329, 0.0882, 0.0911, 0.0948, 0.0943, 0.0737, 0.1299, 0.0953, 0.0852,\n",
              "         0.1146],\n",
              "        [0.1372, 0.0828, 0.0739, 0.0936, 0.0981, 0.0857, 0.1527, 0.0893, 0.0848,\n",
              "         0.1019],\n",
              "        [0.1599, 0.0803, 0.0786, 0.0827, 0.0955, 0.0842, 0.1557, 0.0753, 0.0906,\n",
              "         0.0971],\n",
              "        [0.1468, 0.0705, 0.0999, 0.0901, 0.0843, 0.0968, 0.1053, 0.0927, 0.1067,\n",
              "         0.1071],\n",
              "        [0.2173, 0.0778, 0.1046, 0.0771, 0.0700, 0.0818, 0.1032, 0.0797, 0.1059,\n",
              "         0.0826],\n",
              "        [0.1495, 0.0732, 0.0997, 0.0993, 0.0644, 0.1151, 0.1154, 0.0997, 0.0816,\n",
              "         0.1021],\n",
              "        [0.1374, 0.0835, 0.0788, 0.0893, 0.1092, 0.0937, 0.1268, 0.0823, 0.0900,\n",
              "         0.1090],\n",
              "        [0.1239, 0.0782, 0.0900, 0.0917, 0.0976, 0.1130, 0.1197, 0.0927, 0.0940,\n",
              "         0.0991],\n",
              "        [0.1031, 0.0908, 0.0845, 0.0995, 0.1032, 0.1162, 0.1096, 0.1020, 0.0886,\n",
              "         0.1026],\n",
              "        [0.1522, 0.0895, 0.0753, 0.0991, 0.1009, 0.0829, 0.1143, 0.0852, 0.1061,\n",
              "         0.0946]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "AkJL3a-jYKNV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = LogisticRegressionClassifier(input_size=784, num_classes=10)"
      ],
      "metadata": {
        "id": "AOHQOEAjtpQv"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ePLIwvAFj2zH"
      },
      "cell_type": "code",
      "source": [
        "loss_function = nn.CrossEntropyLoss() # Applies LogSoftmax internally\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics import Accuracy\n",
        "\n",
        "accuracy_function = Accuracy(task='multiclass', num_classes=10)"
      ],
      "metadata": {
        "id": "mmDnHzFUoGvD"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u75Xa5VckuTH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef5a69d1-e00b-4c7b-e146-a687645ac63b"
      },
      "cell_type": "code",
      "source": [
        "num_epochs=3\n",
        "for epoch in range(num_epochs):\n",
        "  for batch_idx ,(images,labels) in enumerate(train_loader):\n",
        "    images = images.reshape(-1,784)\n",
        "\n",
        "    outputs = net(images)\n",
        "    loss = loss_function(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (batch_idx) % 250 == 0:\n",
        "      print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f, Accuracy: %.4f'\n",
        "        %(epoch+1, num_epochs, batch_idx, len(train_loader.dataset)//images.size()[0], loss.item(), accuracy_function(outputs,labels)))\n"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/3], Step [0/1875], Loss: 2.3056, Accuracy: 0.1562\n",
            "Epoch [1/3], Step [250/1875], Loss: 1.7066, Accuracy: 0.8750\n",
            "Epoch [1/3], Step [500/1875], Loss: 1.6588, Accuracy: 0.8125\n",
            "Epoch [1/3], Step [750/1875], Loss: 1.5832, Accuracy: 0.9062\n",
            "Epoch [1/3], Step [1000/1875], Loss: 1.6484, Accuracy: 0.8438\n",
            "Epoch [1/3], Step [1250/1875], Loss: 1.7033, Accuracy: 0.8438\n",
            "Epoch [1/3], Step [1500/1875], Loss: 1.6091, Accuracy: 0.8438\n",
            "Epoch [1/3], Step [1750/1875], Loss: 1.6142, Accuracy: 0.8750\n",
            "Epoch [2/3], Step [0/1875], Loss: 1.5605, Accuracy: 0.9062\n",
            "Epoch [2/3], Step [250/1875], Loss: 1.6061, Accuracy: 0.9062\n",
            "Epoch [2/3], Step [500/1875], Loss: 1.6323, Accuracy: 0.8125\n",
            "Epoch [2/3], Step [750/1875], Loss: 1.5466, Accuracy: 0.9688\n",
            "Epoch [2/3], Step [1000/1875], Loss: 1.5981, Accuracy: 0.8750\n",
            "Epoch [2/3], Step [1250/1875], Loss: 1.5736, Accuracy: 0.9688\n",
            "Epoch [2/3], Step [1500/1875], Loss: 1.5138, Accuracy: 0.9688\n",
            "Epoch [2/3], Step [1750/1875], Loss: 1.5740, Accuracy: 0.9375\n",
            "Epoch [3/3], Step [0/1875], Loss: 1.5690, Accuracy: 0.9062\n",
            "Epoch [3/3], Step [250/1875], Loss: 1.5673, Accuracy: 0.9688\n",
            "Epoch [3/3], Step [500/1875], Loss: 1.5170, Accuracy: 0.9688\n",
            "Epoch [3/3], Step [750/1875], Loss: 1.5412, Accuracy: 0.9375\n",
            "Epoch [3/3], Step [1000/1875], Loss: 1.5946, Accuracy: 0.9062\n",
            "Epoch [3/3], Step [1250/1875], Loss: 1.5618, Accuracy: 0.9062\n",
            "Epoch [3/3], Step [1500/1875], Loss: 1.5251, Accuracy: 0.9688\n",
            "Epoch [3/3], Step [1750/1875], Loss: 1.5555, Accuracy: 0.9375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "def get_accuracy(model, loader):\n",
        "  model.eval()\n",
        "  all_predictions = []\n",
        "  all_labels = []\n",
        "  with torch.no_grad(): #Uses less GPU memory and is faster\n",
        "    for images,labels in tqdm(loader):\n",
        "      images = images.reshape(-1,28*28)\n",
        "      labels = labels\n",
        "\n",
        "      output = model(images)\n",
        "      all_predictions.append(output)\n",
        "      all_labels.append(labels)\n",
        "\n",
        "  #torch.cat concats tensors along new dimension\n",
        "  print('Accuracy:', accuracy_function(torch.cat(all_predictions), torch.cat(all_labels)).item())"
      ],
      "metadata": {
        "id": "O2_CfOTQZCRq"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_accuracy(net, train_loader)"
      ],
      "metadata": {
        "id": "lS8a2rt3Zhyn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20238838-8bc4-471c-eb2d-b98a86c3e1d6"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1875/1875 [00:09<00:00, 197.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9234499931335449\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "beDB4Sx0ujAx"
      }
    },
    {
      "metadata": {
        "id": "DTPvMW5jHB9X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c67288bf-bac4-44c9-d6f1-ae9b4aad6363"
      },
      "cell_type": "code",
      "source": [
        "test_data = dsets.MNIST(root = './data', train = False, transform = transforms.ToTensor())\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_data, batch_size = 128, shuffle = False)\n",
        "\n",
        "print(test_data.__len__())\n"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_accuracy(net, test_loader)"
      ],
      "metadata": {
        "id": "OBQxNJaGavbA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5751b2f2-34eb-48e3-aca2-a30202741e52"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:01<00:00, 52.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9240000247955322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise: Solve the problem with MLP"
      ],
      "metadata": {
        "id": "b-oBcCFns8yy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Solutions\n"
      ],
      "metadata": {
        "id": "mVNtQutinhMj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################################"
      ],
      "metadata": {
        "id": "opTs25P8nnro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MLP task solution (Spoiler inside!)"
      ],
      "metadata": {
        "id": "kt5yairbmCSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super().__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        nn.Linear(input_size, hidden_size),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_size, num_classes),\n",
        "        # nn.Softmax(dim=-1), # the nn.CrossEntropyLoss() function applies LogSoftmax internally, so no softmax necessery!\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    return self.net(x)"
      ],
      "metadata": {
        "id": "tRgELCobmB51"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p93vuWsq1vZB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}